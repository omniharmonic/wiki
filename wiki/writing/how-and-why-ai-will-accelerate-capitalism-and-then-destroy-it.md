---
title: "How and Why AI Will Accelerate Capitalism and Then Destroy It"
type: writing
author: "Benjamin Life"
visibility: public
status: published
publication: "omniharmonic (Substack)"
url: ""
tags: [ai, technology, capitalism, post-capitalism, localism, commons, governance, democracy, web3, bioregionalism]
published: ""
updated: "2026-02-04"
description: "An analysis of how AI simultaneously accelerates capitalism's extractive logic toward epistemic collapse and digital enclosure while also driving marginal costs toward zero, enabling an unprecedented 'digital un-enclosure' that could catalyze localized, democratic, post-capitalist futures."
aliases: ["How and Why AI Will Accelerate Capitalism and Then Destroy It"]
related: []
---

# How and Why AI Will Accelerate Capitalism and Then Destroy It

If you're experiencing whiplash from the onslaught of exponential accelerationism, you're not alone.

We're hitting recursive inflection points across multiple parallel systems. AI tool releases now follow weekly cadences—each promising to revolutionize domains from creative expression to scientific discovery. Meanwhile, political chaos unfolds faster than sense-making institutions can process. The news cycle has become a perpetual crisis machine where each emergency eclipses the last before we can grasp its implications.

This isn't accidental. It's the logical endpoint of capitalism's core imperative: infinite growth on a finite planet through ever-deeper resource extraction—attention, energy, political power, compute. Like financial derivatives that abstracted value relationships into Wall Street casino gambling, triggering runaway wealth concentration and middle-class strip-mining, AI is unleashing feedback loops that will fundamentally reorganize entire domains of society, from governance to economics to the social contract itself.

But here's the crucial difference: derivatives merely reshuffled existing value. AI creates entirely new productive capacities while threatening to eliminate the human labor that historically anchored capitalism. Even tech leaders like Sam Altman acknowledge these macro-disruptions exceed any single actor's control. The market's "invisible hand," already struggling with global complexity, faces challenges that exceed its coordination capacity.

This exemplifies what Garrett Hardin misnamed the "tragedy of the commons"—more accurately described as [[multi-polar-traps|multi-polar traps]]— systemic dynamics in which rational individual behavior produces collectively catastrophic outcomes. Nations race to develop AI despite recognizing existential risks. Companies rush to market because hesitation means obsolescence. Users adopt tools that undermine long-term well-being for shortsighted benefit. We're witnessing rivalrous game theory multiplied by exponential technologies, where players optimize for winning even when victory destroys the game itself.

We're living through technological transformation comparable to industrialization—compressed from generations into years. The Industrial Revolution allowed gradual institutional adaptation. We're experiencing equivalent disruption in machine time, where AI capabilities double every few months while human institutions operate on political timescales. Our Pleistocene brains didn't evolve for this complexity, yet our recursive adaptability—cultural evolution and technological augmentation—drives us forward even as our cognitive hardware strains under consequences we can barely comprehend.

## The Internet is Dead. We Have Killed It.

Late-stage capitalism accelerated by AI has triggered what media theorists call [[epistemic-collapse|epistemic collapse]]—breakdown, not just in knowable facts, but in the categories through which we understand reality. "Dead internet theory" has graduated from conspiracy to documented phenomenon: bot traffic is estimated to comprise over 40% of web activity and synthetic content is exploding exponentially.

The implications transcend statistics. AI marketing systems now flood digital spaces with content optimized for engagement over truth, producing sophisticated mimicry of human emotional responses, political opinions, and social relationships. We're inhabiting what Jean Baudrillard called "simulacra"—copies without originals—where distinguishing authentic expression from algorithmic generation becomes not just difficult but potentially meaningless.

This synthetic flood has accelerated what could be called "epistemic learned helplessness"—cognitive surrender when the burden of distinguishing truth from fabrication becomes overwhelming. When deepfakes achieve photorealism, when AI manipulates every interaction, when bots converse indistinguishably from humans, we lose "common knowledge"—a foundational shared understanding of our shared reality.

Capitalism's worst tendencies—attention commodification, human and ecological value reduced to lines on a spreadsheet, profit prioritization over truth—achieve exponential amplification through AI systems optimizing metrics rather than meaning. Social platforms promising human connection have become automated engagement farms where AI generates content to capture AI-curated attention, creating self-reinforcing loops that increasingly exclude genuine human participation. We're witnessing digital enclosure's final stage: even authentic expression gets monetized and automated, transformed into training data for systems that will replace the human creativity they learned from.

## The Great Un-Enclosure: When Costs Drop to Zero

Yet within this dystopia lies capitalism's fatal contradiction. AI drives marginal production costs toward zero across knowledge domains—content creation, software development, analysis, research. This isn't mere efficiency; it's fundamental economic transformation. When sophisticated analysis requiring expert teams becomes individually accessible, when complex applications get prototyped in hours not months, when personalized services deliver at near-zero marginal cost, traditional relationships between capital, labor, and value disintegrate.

Open source models, democratized development tools, and distributed AI capabilities create what we might call "[[digital-un-enclosure|digital un-enclosure]]." Historical patterns show technologies initially concentrating power before ultimately distributing it—printing presses empowered publishers before enabling mass literacy, the internet benefited corporations before spawning countless entrepreneurs and activists. But AI represents qualitatively different democratization because it doesn't just distribute existing capabilities—it creates entirely new productive capacity.

This process resists re-enclosure through traditional capitalist mechanisms. Once capabilities become open source and freely distributable, they cannot be recaptured. The same AI threatening job automation simultaneously provides individuals and communities with tools previously exclusive to massive corporations. We're seeing what economist Paul Mason calls "post-capitalist dynamics"—breakdowns in scarcity-ownership-profit relationships when technologies reproduce infinitely at near-zero cost.

For the first time in modern history, regular people access the same building blocks of digital power once monopolized by tech giants. Teenagers command computational capabilities exceeding the world's most powerful supercomputers from decades past. Small communities can deploy AI-assisted software rivaling Fortune 500 systems. This represents a fundamental shift in the technological capability-economic power relationship.

Simultaneously, power asymmetries are magnifying and collapsing. While AI initially concentrates resources among computational elites, rapid democratization—paralleling how mobile technology enabled Global South leapfrogging—creates new possibilities for distributed autonomy. The same dynamics creating tech billionaires also generate conditions for their obsolescence.

In this landscape, anything enclosed can be un-enclosed. Communities can build sophisticated platform alternatives. Individuals can create tools previously requiring venture backing. The digital means of production are being democratized in ways Marx could have never imagined, approaching what theorists have jokingly dubbed "fully automated luxury communism"—a post-scarcity society where democratically controlled technology meets human needs rather than market mechanisms.

## The Late Stage Endgame

Shared realities dissolve as acceleration continues across domains simultaneously, creating cascading institutional failures as traditional structures prove inadequate to meet the velocity of exponential change. Governments struggle regulating technologies they don't understand. Educational institutions grapple with AI tools making assessment meaningless. Economic systems confront mass automation implications. These aren't temporary adjustments—they're symptoms of deeper misalignment between technology and society, between society and itself.

The "institutional lag" we're experiencing today, the inability of institutions to manage the rate of extraction and centralization, is in fact the long tail of extractive capitalism itself. AI capabilities double annually while our legal frameworks, operating on two and four year cycles, were captured long ago. This creates dangerous gaps where powerful technologies operate in regulatory and ethical vacuums. New elites will leverage these transitions for power accumulation, following patterns from Gilded Age robber barons through internet-era tech titans.

However, our future trajectory depends on whether open source and decentralized technologies outpace re-enclosure attempts. This represents a "race condition" in social evolution—will democratizing technologies spread faster than authoritarian adaptation?

Yet beyond technological anti-authoritarianism lies an even deeper challenge. We're approaching the point where nothing on centralized platforms can be believed. This epistemic crisis necessitates locally attested networks and direct peer-to-peer trust relationships. Solutions require not better content moderation by centralized authorities—fundamentally flawed approaches concentrating power while failing to address underlying problems—but decentralized systems where community networks verify provenance and authenticity rather than corporate gatekeepers. Blockchain's most important application may be cryptographic information provenance, creating verifiable authenticity chains when synthetic content becomes indistinguishable from human creation.

This shift demands what anthropologist James C. Scott calls "local knowledge"—context-specific understanding emerging from lived community experience. Centralized platforms optimize for global engagement but lose nuanced social cues and trust relationships enabling authentic communication. Digital discourse's future may depend on rebuilding these local knowledge networks, enhanced by AI tools augmenting rather than replacing human social intelligence.

## AI-Enabled Localization

Paradoxically, the same AI threatening global homogenization enables unprecedented [[localism|localization]]. This represents a fundamental shift from centuries-old economies of scale driving centralization toward "economies of scope"—efficiently producing highly customized solutions for specific communities and contexts.

Rather than relying on centralized monopolies for one-size-fits-all solutions, communities can build bespoke systems tailored to specific needs, values, and cultural contexts. This "vibe coding" revolution—AI assistants translating human intentions into working software—means communities can easily build peer-to-peer and locally hosted technologies reflecting their own social arrangements and priorities.

Consider server racks in community centers and local food cooperatives building supply chain management systems. Neighborhoods creating networks with governance rules reflecting local values. [[bioregionalism|Bioregions]] developing economic platforms prioritizing ecological sustainability over profit maximization. Now, the forces that wish to enclose our digital and physical [[commons-governance|commons]] are only as strong as our unwillingness to create alternatives—and AI exponentially eases alternative creation.

This transcends technological decentralization toward "[[technological-sovereignty|technological sovereignty]]"—community capacity to shape technological environments rather than being shaped by technologies designed elsewhere for other purposes. Local communities can build networks, economies, and governance tools embodying their values while serving their specific needs. This could reverse centuries of technological centralization, creating what Murray Bookchin called "libertarian municipalism"—democratic, ecological, human-scale alternatives to both capitalism and state socialism.

Implications extend beyond digital tools to physical infrastructure. AI-assisted design and manufacturing could enable local production from electronics to pharmaceuticals, reducing global supply chain dependence and creating more resilient, self-sufficient communities. This represents a potential return to what E.F. Schumacher called "appropriate technology"—environmentally sustainable, socially equitable, locally controllable tools.

## Where Game Theory Breaks: The Social Singularity

We're approaching a [[social-singularity|social singularity]]—the massive societal reorganization event horizon beyond which current social and economic models become fundamentally inadequate. This represents breakdown points where traditional game theory loses predictive power because recursive technological feedback loops rewrite game rules in real-time.

Borrowed from physics, singularity describes points where normal rules break down and prediction becomes impossible. In social systems, this occurs when the rate of change exceeds existing institutional adaptive capacity, creating phase transitions fundamentally altering society's structure. Early signs include traditional media business model collapse, education and credentialing obsolescence, and new work and social organization forms not fitting existing categories.

A new social contract is urgently needed. The current AI development trajectories offered by [AI 2027](https://ai-2027.com/) suggest two primary pathways, neither including significant civic uprising or democratic participation in shaping our technological, economic and societal future. First: corporate techno-feudalism where small numbers of AI companies control society's fundamental infrastructure, creating state-controlled digital authoritarianism—surveillance systems monitoring and controlling every human behavior aspect in security and efficiency's name.
Second: the annihilation of the human race.

Yet history suggests technological revolutions often catalyze unexpected social movements. Printing presses contributed to Protestant Reformation and Scientific Revolution. The Industrial Revolution sparked labor movements and democratic uprisings. The Internet enabled movements from Occupy to the Arab Spring to #MeToo. Taiwan's Sunflower Movement rose around seemingly simple telecommunications legislation prioritizing Chinese companies—becoming a broader digital democracy and technological sovereignty movement, pioneering participatory governance and civic technology forms.

Similarly, movements imagining and building post-AI futures could spark broader democratic participation in both governance and economic re-imagination. This re-imagining extends far beyond simply AI government regulation toward actively building alternative systems embodying democratic, egalitarian, ecological, humanistic, and protopian values. It demands what historian Rebecca Solnit calls "hope in the dark"—capacity to act constructively despite uncertain outcomes, building desired futures rather than simply resisting feared ones.

And with this optimism, we must be incredibly precise. The window for "Shambhala Warriors" to enter the halls of power and dismantle the ideologies of war may be narrow. Once AI systems become sufficiently powerful and entrenched, democratic alternative possibilities may foreclose. But right now, while AI capabilities develop and open source alternatives exist, opportunities remain to shape technological development in more democratic directions.

## The Choice Before Us

AI holds the potential to exponentially accelerate humanity as either a democratizing force or as the ultimate totalitarian foundation. The difference lies not in the technology itself but in the control, development, and embedded values in how it is designed and deployed. AI concentrated among a few centralized monoliths—corporate or governmental—risks creating new global governance forms operating beyond democratic accountability, what political scientist Shoshana Zuboff calls "surveillance capitalism" taken to logical extremes.

But distributed, open AI capabilities can enhance democratic participation and community self-determination unprecedentedly. AI could enable new collective intelligence forms where communities process complex information and make decisions more effectively than traditional democratic institutions. It could facilitate what political theorist Helene Landemore calls "open democracy"—more inclusive, deliberative, responsive governance leveraging collective wisdom rather than relying on representative elites.

Technology is never neutral—it embodies creators' and deployers' values, power structures, and social relationships. The question is not whether AI will be political, but what politics it will embody. Will it reinforce existing hierarchies and inequalities, or create new possibilities for human flourishing and democratic participation?

We can participate in this transformation by consciously using AI for the benefit of the [[commons-governance|commons]] rather than utilizing AI systems to extract value from our attention, data, or labor. This means actively choosing to ship open source software, empower post-capitalist cooperative economies, and refuse digital enclosure, leveraging AI as a tool of communal liberation at a greater scale than it can be leveraged as a mechanism of control.

The path forward requires building alternatives while we still can. Every open source AI model released, every decentralized platform created, every local community developing technological sovereignty represents small victories against digital feudalism. But it also requires broader cultural and political mobilization—what social movement theorist Doug McAdam calls "cognitive liberation," collective recognition that change is both necessary and possible.

This ultimately concerns what kind of society we want. Do we want AI augmenting human capabilities and supporting democratic participation, or AI replacing human agency and concentrating power among technological elites? Do we want technology serving human flourishing and ecological sustainability, or technology treating humans and nature as resources to optimize for profit?

We are materially creating the future through the algorithms we use, platforms we support, code we write, and communities we build. These seemingly individual decisions aggregate into technological development's collective trajectory.

AI will transform capitalism—that transformation is underway. The question before us is whether or not that transformation leads to more democratic, localized, human-centered futures or new concentrated power and authoritarian control.

Our collective future depends on the choices we make now, while windows for democratic participation in this transformation remain open. We stand at a crossroads, an inflection point at which our choices will determine if our ultimate technological achievement is a tool for collective liberation or a tool for collective enslavement.

The future isn't predetermined—its determined by what you choose.

Are you building for what comes next or are you trying to make a quick profit on a sinking ship?
